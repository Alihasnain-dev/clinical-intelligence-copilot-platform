{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1-instructions",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "To train the model and generate the `vision_model.pth` file, you need to run all the cells in this notebook. You can do this by clicking the \"Run All\" button in the toolbar above, or by pressing `Ctrl+Alt+Enter`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2-title",
   "metadata": {},
   "source": [
    "# Train Multi-Label Computer Vision Model on Google Colab\n",
    "\n",
    "This notebook trains a multi-label classifier on the Chest X-ray dataset. It is designed to be run in a Google Colab environment to leverage free GPU resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3-pip-install",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
      "Requirement already satisfied: azure-storage-blob in /usr/local/lib/python3.12/dist-packages (12.27.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: azure-core>=1.30.0 in /usr/local/lib/python3.12/dist-packages (from azure-storage-blob) (1.36.0)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in /usr/local/lib/python3.12/dist-packages (from azure-storage-blob) (43.0.3)\n",
      "Requirement already satisfied: isodate>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from azure-storage-blob) (0.7.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: requests>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from azure-core>=1.30.0->azure-storage-blob) (2.32.4)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=2.1.4->azure-storage-blob) (2.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob) (2.23)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-storage-blob) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-storage-blob) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-storage-blob) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-storage-blob) (2025.10.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision pandas azure-storage-blob scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from azure.storage.blob import BlobServiceClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5-creds-text",
   "metadata": {},
   "source": [
    "## 1. Enter Your Azure Credentials\n",
    "\n",
    "Please enter your Azure Storage Account name and a SAS token with read/list permissions for the blob service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6-creds-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "STORAGE_ACCOUNT_NAME = \"clinicaldatalake25\"  # Your storage account name\n",
    "SAS_TOKEN = \"sv=2024-11-04&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2025-11-19T06:23:06Z&st=2025-11-18T22:08:06Z&spr=https&sig=RDdiKrvqJzkeU4AsMSvUCs4pSJqfrj3Lbs%2F%2B56PBbWk%3D\"  # Paste your Blob SAS Token here\n",
    "IMAGE_CONTAINER_NAME = \"images\"\n",
    "LABELS_CONTAINER_NAME = \"labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7-auth-check",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing connection to clinicaldatalake25...\n",
      "✅ Connection successful! SAS Token is valid.\n",
      "✅ Container 'ml-models' created.\n"
     ]
    }
   ],
   "source": [
    "if not SAS_TOKEN:\n",
    "    raise ValueError(\"Please paste your SAS_TOKEN into the cell above.\")\n",
    "\n",
    "storage_account_url = f\"https://{STORAGE_ACCOUNT_NAME}.blob.core.windows.net\"\n",
    "blob_service_client = BlobServiceClient(account_url=storage_account_url, credential=SAS_TOKEN)\n",
    "\n",
    "# VALIDATION STEP\n",
    "try:\n",
    "    print(f\"Testing connection to {STORAGE_ACCOUNT_NAME}...\")\n",
    "    # Try to list containers to verify Read permissions\n",
    "    containers = list(blob_service_client.list_containers(results_per_page=1))\n",
    "    print(\"✅ Connection successful! SAS Token is valid.\")\n",
    "    \n",
    "    # Ensure the upload container exists NOW, so we don't fail later\n",
    "    upload_container = \"ml-models\"\n",
    "    try:\n",
    "        blob_service_client.create_container(upload_container)\n",
    "        print(f\"✅ Container '{upload_container}' created.\")\n",
    "    except Exception:\n",
    "        print(f\"✅ Container '{upload_container}' already exists.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ CONNECTION FAILED: {e}\")\n",
    "    raise RuntimeError(\"Invalid SAS Token or Connection. Please fix credentials before proceeding.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8-load-labels",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Download and load labels\n",
    "try:\n",
    "    labels_container_client = blob_service_client.get_container_client(LABELS_CONTAINER_NAME)\n",
    "    blob_client = labels_container_client.get_blob_client(\"Data_Entry_2017.csv\")\n",
    "    downloader = blob_client.download_blob()\n",
    "    labels_df = pd.read_csv(io.BytesIO(downloader.readall()))\n",
    "    print(\"Labels loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading labels: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9-process-labels",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15 unique classes.\n"
     ]
    }
   ],
   "source": [
    "# Get all unique labels\n",
    "all_labels_str = '|'.join(labels_df['Finding Labels'].dropna())\n",
    "all_labels = sorted(list(set(all_labels_str.split('|'))))\n",
    "label_to_int = {label: i for i, label in enumerate(all_labels)}\n",
    "num_classes = len(all_labels)\n",
    "print(f\"Found {num_classes} unique classes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10-get-images",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing images in blob storage...\n",
      "Found 30000 images in blob storage.\n"
     ]
    }
   ],
   "source": [
    "# Get list of images from blob storage\n",
    "print(\"Listing images in blob storage...\")\n",
    "image_container_client = blob_service_client.get_container_client(IMAGE_CONTAINER_NAME)\n",
    "blob_list = [blob.name for blob in image_container_client.list_blobs()]\n",
    "images_df = pd.DataFrame(blob_list, columns=['blob_path'])\n",
    "images_df['Image Index'] = images_df['blob_path'].apply(lambda x: os.path.basename(x))\n",
    "print(f\"Found {len(images_df)} images in blob storage.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "11-filter-labels",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the labels to only include images that are actually in our blob storage\n",
    "clean_labels_df = labels_df[labels_df['Image Index'].isin(images_df['Image Index'])].copy()\n",
    "clean_labels_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12-merge-sample",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size (30000) is larger than 2000. Sampling 2000 images...\n",
      "Final dataset size: 2000\n"
     ]
    }
   ],
   "source": [
    "# Merge to get the full blob path for each labeled image\n",
    "df = pd.merge(images_df, clean_labels_df, on='Image Index', how='inner')\n",
    "\n",
    "# SAMPLING STEP\n",
    "# Limit the dataset size to ensure Colab can handle the training\n",
    "SAMPLE_SIZE = 2000\n",
    "if len(df) > SAMPLE_SIZE:\n",
    "    print(f\"Dataset size ({len(df)}) is larger than {SAMPLE_SIZE}. Sampling {SAMPLE_SIZE} images...\")\n",
    "    df = df.sample(n=SAMPLE_SIZE, random_state=42).reset_index(drop=True)\n",
    "else:\n",
    "    print(f\"Dataset size ({len(df)}) is within limits. Using full dataset.\")\n",
    "\n",
    "print(f\"Final dataset size: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13-split-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "14-dataset-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChestXrayDataset(Dataset):\n",
    "    def __init__(self, df, container_client, label_map, transform=None):\n",
    "        self.df = df\n",
    "        self.container_client = container_client\n",
    "        self.label_map = label_map\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = row['blob_path']\n",
    "        \n",
    "        blob_client = self.container_client.get_blob_client(img_path)\n",
    "        downloader = blob_client.download_blob()\n",
    "        image_bytes = downloader.readall()\n",
    "        image = Image.open(io.BytesIO(image_bytes)).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Create the multi-hot encoded label tensor\n",
    "        labels = row['Finding Labels'].split('|')\n",
    "        label_tensor = torch.zeros(len(self.label_map), dtype=torch.float32)\n",
    "        for label in labels:\n",
    "            if label in self.label_map:\n",
    "                label_tensor[self.label_map[label]] = 1.0\n",
    "        \n",
    "        return image, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "15-transforms",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "train_dataset = ChestXrayDataset(train_df, image_container_client, label_to_int, transform=data_transforms['train'])\n",
    "val_dataset = ChestXrayDataset(val_df, image_container_client, label_to_int, transform=data_transforms['val'])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16-model-def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ResNet50 model...\n",
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Use ResNet50 as per the project architecture requirements\n",
    "print(\"Loading ResNet50 model...\")\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "17-optimizer",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18-training-loop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training...\n",
      "Epoch [1/3], Batch [10/50], Loss: 0.1586\n",
      "Epoch [1/3], Batch [20/50], Loss: 0.2130\n",
      "Epoch [1/3], Batch [30/50], Loss: 0.2848\n",
      "Epoch [1/3], Batch [40/50], Loss: 0.1666\n",
      "Epoch [1/3], Batch [50/50], Loss: 0.1858\n",
      "--- End of Epoch [1/3], Average Training Loss: 0.2390 ---\n",
      "Epoch [2/3], Batch [10/50], Loss: 0.1793\n",
      "Epoch [2/3], Batch [20/50], Loss: 0.2537\n",
      "Epoch [2/3], Batch [30/50], Loss: 0.2150\n",
      "Epoch [2/3], Batch [40/50], Loss: 0.2361\n",
      "Epoch [2/3], Batch [50/50], Loss: 0.2063\n",
      "--- End of Epoch [2/3], Average Training Loss: 0.2063 ---\n",
      "Epoch [3/3], Batch [10/50], Loss: 0.1888\n",
      "Epoch [3/3], Batch [20/50], Loss: 0.1687\n",
      "Epoch [3/3], Batch [30/50], Loss: 0.1795\n",
      "Epoch [3/3], Batch [40/50], Loss: 0.1926\n",
      "Epoch [3/3], Batch [50/50], Loss: 0.1593\n",
      "--- End of Epoch [3/3], Average Training Loss: 0.2006 ---\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting model training...\")\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (images, labels) in enumerate(train_dataloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{len(train_dataloader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataloader)\n",
    "    print(f'--- End of Epoch [{epoch+1}/{num_epochs}], Average Training Loss: {epoch_loss:.4f} ---')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "19-save-model",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to vision_model.pth in the same directory as this notebook.\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), 'vision_model.pth')\n",
    "print(\"Model saved to vision_model.pth in the same directory as this notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20-verify-text",
   "metadata": {},
   "source": [
    "## 2. Model Saved Locally\n",
    "\n",
    "The trained model has been saved as `vision_model.pth` in the same directory as this notebook. You can find it in the file explorer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "21-ls-check",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 92268\n",
      "drwxr-xr-x 1 root root     4096 Nov 17 14:29 sample_data\n",
      "-rw-r--r-- 1 root root 94474717 Nov 18 23:18 vision_model.pth\n"
     ]
    }
   ],
   "source": [
    "# List files in the current directory to confirm the model is saved\n",
    "!ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22-upload-text",
   "metadata": {},
   "source": [
    "## 3. Upload Model to Azure Blob Storage\n",
    "\n",
    "This step uploads the trained model back to Azure so you can use it in your API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "23-upload-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Uploading model to Azure Blob Storage...\n",
      "Container 'ml-models' already exists (or access denied to create).\n",
      "SUCCESS: Model uploaded to container 'ml-models' as 'vision/vision_model.pth'\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nUploading model to Azure Blob Storage...\")\n",
    "\n",
    "MODEL_CONTAINER_NAME = \"ml-models\"\n",
    "BLOB_NAME = \"vision/vision_model.pth\"\n",
    "LOCAL_MODEL_PATH = \"vision_model.pth\"\n",
    "\n",
    "try:\n",
    "    # Create the container if it doesn't exist\n",
    "    try:\n",
    "        container_client = blob_service_client.create_container(MODEL_CONTAINER_NAME)\n",
    "        print(f\"Container '{MODEL_CONTAINER_NAME}' created.\")\n",
    "    except Exception:\n",
    "        # Container likely already exists\n",
    "        container_client = blob_service_client.get_container_client(MODEL_CONTAINER_NAME)\n",
    "        print(f\"Container '{MODEL_CONTAINER_NAME}' already exists (or access denied to create).\")\n",
    "\n",
    "    # Get blob client\n",
    "    blob_client = container_client.get_blob_client(BLOB_NAME)\n",
    "\n",
    "    # Upload\n",
    "    with open(LOCAL_MODEL_PATH, \"rb\") as data:\n",
    "        blob_client.upload_blob(data, overwrite=True)\n",
    "\n",
    "    print(f\"SUCCESS: Model uploaded to container '{MODEL_CONTAINER_NAME}' as '{BLOB_NAME}'\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Failed to upload model to Azure. Details: {e}\")\n",
    "    print(\"You may need to manually download 'vision_model.pth' from the file explorer on the left.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
